\section{Introduction}

Most prominent vision datasets are afflicted by \emph{contextual bias}. For example, ``microwave" typically is found in kitchens, which also contain objects like ``refrigerator" and ``oven."  Such co-occurrence patterns may inadvertently induce contextual bias in datasets, which could consequently seep into models trained on them. When models overly rely on context, they may not generalize to settings where typical co-occurrence patterns are absent. The original paper by Singh et al.~\cite{Singh_2020_CVPR} proposes two methods for mitigating such contextual biases and improving the robustness of the learnt feature representations. The paper demonstrates their methods on multi-label object and attribute classification tasks, using the COCO-Stuff~\cite{caesar2018cvpr}, DeepFashion~\cite{liuLQWTcvpr16DeepFashion}, Animals with Attributes (AwA)~\cite{AwA}, and UnRel~\cite{Peyre17} datasets. Our exploration centers on four main directions:\\
\\
First, we trained the baseline classifier presented in the paper (Section~\ref{sec:baselineimplementation} for implementation and training details; Sections~\ref{sec:evaluation}-\ref{sec:baselineresults} for results). Due to likely implementation discrepancies, our results differed from the original paper by 0.6--3.1\% mAP on COCO-Stuff, by 0.7--1.4\% top-3 recall on DeepFashion, and by 0.1--3.2\% mAP on AwA (Table~\ref{tab:mainresults}). We ran a hyperparameter search (Appendix~\ref{sec:hyperparametersearch}), which yielded a significant (1.4--3.6\%) improvement on DeepFashion.\\
\\
Next, we identified the \emph{biased categories} in each dataset, i.e., visual categories that suffer from contextual bias. We followed the proposed method of using the baseline classifier to identify these categories, and discovered that the classifier implementation has a non-trivial effect. For COCO-Stuff, 18 of the top-20 categories we identified matched the original paper's top-20 categories (10 on DeepFashion, 18 on AwA; Section~\ref{sec:biasedcategories}). Nevertheless, the categories we identified appear reasonable  (e.g., ``fork" co-occurs with ``dining table"; Appendix~\ref{sec:biasedcategoriesapp}). As training and evaluation of most methods depend on the biased categories, we used the paper's biased categories for subsequent experiments.\\
\\
Third, we checked the main claim of the paper, that the proposed \emph{CAM-based} and \emph{feature-split} methods help improve recognition of biased categories in the absence of their context (Section~\ref{sec:stage2}). On COCO-Stuff, DeepFashion, and UnRel, we were able to reproduce the improvements gained from the proposed \textit{feature-split} method towards reducing contextual bias, whereas on AwA, we saw a drop in performance. The proposed \textit{CAM-based} method, which was only applied to COCO-Stuff, also helped reduce contextual bias, though not as significantly as the \textit{feature-split} method. For the  method, we reproduced the original paper's results to within 0.5\% mAP (Section~\ref{sec:mainresults}). We also successfully reproduced the paper's weight similarity analysis, as well as the qualitative analyses with class activation maps (CAMs)~\cite{zhou2015cnnlocalization}.\\
\\
Lastly, we ran additional experiments and ablation studies (Section~\ref{sec:addanalyses}). These revealed that the regularization term in the \emph{CAM-based} method and the weighted loss in the \emph{feature-split} method are central to the methods' performance. We also observed that varying the feature subspace size influences the \emph{feature-split} method's accuracy.
