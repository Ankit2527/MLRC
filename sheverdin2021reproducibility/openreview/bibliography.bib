@misc{github-gana-fact-ai,
  author = {Anonymous Authors},
  title = {gana-fact-ai},
  year = {2021},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/GANA-FACT-AI/gana-fact-ai}},
  commit = {4f57d6a0e4c030202a07a60bc1bb1ed1544bf679}
}

@article{DBLP:journals/corr/GulrajaniAADC17,
  author    = {Ishaan Gulrajani and
               Faruk Ahmed and
               Mart{\'{\i}}n Arjovsky and
               Vincent Dumoulin and
               Aaron C. Courville},
  title     = {Improved Training of Wasserstein GANs},
  journal   = {CoRR},
  volume    = {abs/1704.00028},
  year      = {2017},
  url       = {http://arxiv.org/abs/1704.00028},
  archivePrefix = {arXiv},
  eprint    = {1704.00028},
  timestamp = {Mon, 13 Aug 2018 16:47:43 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/GulrajaniAADC17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{U-net,
  author    = {Olaf Ronneberger and
               Philipp Fischer and
               Thomas Brox},
  title     = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  journal   = {CoRR},
  volume    = {abs/1505.04597},
  year      = {2015},
  url       = {http://arxiv.org/abs/1505.04597},
  archivePrefix = {arXiv},
  eprint    = {1505.04597},
  timestamp = {Mon, 13 Aug 2018 16:46:52 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/RonnebergerFB15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{xiang2020interpretable,
      title={Interpretable Complex-Valued Neural Networks for Privacy Protection}, 
      author={Liyao Xiang and Haotian Ma and Hao Zhang and Yifan Zhang and Jie Ren and Quanshi Zhang},
      year={2020},
      eprint={1901.09546},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{pmlr-v70-arjovsky17a, 
    title = {{W}asserstein Generative Adversarial Networks}, 
    author = {Martin Arjovsky and Soumith Chintala and L{\'e}on Bottou}, 
    booktitle = {Proceedings of the 34th International Conference on Machine Learning}, 
    pages = {214--223}, 
    year = {2017}, 
    editor = {Doina Precup and Yee Whye Teh}, 
    volume = {70}, 
    series = {Proceedings of Machine Learning Research},
    address = {International Convention Centre, Sydney, Australia}, 
    month = {06--11 Aug}, 
    publisher = {PMLR}, 
    pdf = {http://proceedings.mlr.press/v70/arjovsky17a/arjovsky17a.pdf}, 
    url = {http://proceedings.mlr.press/v70/arjovsky17a.html}, 
    abstract = {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to different distances between distributions.} 
}

@article{paszke2017automatic,
  title={Automatic differentiation in PyTorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  year={2017}
}

@article{DBLP:journals/corr/TrabelsiBSSSMRB17,
  author    = {Chiheb Trabelsi and
               Olexa Bilaniuk and
               Dmitriy Serdyuk and
               Sandeep Subramanian and
               Jo{\~{a}}o Felipe Santos and
               Soroush Mehri and
               Negar Rostamzadeh and
               Yoshua Bengio and
               Christopher J. Pal},
  title     = {Deep Complex Networks},
  journal   = {CoRR},
  volume    = {abs/1705.09792},
  year      = {2017},
  url       = {http://arxiv.org/abs/1705.09792},
  archivePrefix = {arXiv},
  eprint    = {1705.09792},
  timestamp = {Mon, 13 Aug 2018 16:47:56 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/TrabelsiBSSSMRB17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/HeZRS15,
      author    = {Kaiming He and
                   Xiangyu Zhang and
                   Shaoqing Ren and
                   Jian Sun},
      title     = {Deep Residual Learning for Image Recognition},
      journal   = {CoRR},
      volume    = {abs/1512.03385},
      year      = {2016},
      url       = {http://arxiv.org/abs/1512.03385},
      archivePrefix = {arXiv},
      eprint    = {1512.03385},
      timestamp = {Wed, 17 Apr 2019 17:23:45 +0200},
      biburl    = {https://dblp.org/rec/journals/corr/HeZRS15.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{lecun1998gradient,
    author = {Lecun, Yann and Bottou, Leon and Bengio, Y. and Haffner, Patrick},
    year = {1998},
    month = {12},
    pages = {2278 - 2324},
    title = {Gradient-Based Learning Applied to Document Recognition},
    volume = {86},
    journal = {Proceedings of the IEEE},
    doi = {10.1109/5.726791}
}

@misc{simonyan2015deep,
      title={Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
      author={Karen Simonyan and Andrew Zisserman},
      year={2015},
      eprint={1409.1556},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{NIPS2012_c399862d,
     author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
     booktitle = {Advances in Neural Information Processing Systems},
     editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
     pages = {1097--1105},
     publisher = {Curran Associates, Inc.},
     title = {ImageNet Classification with Deep Convolutional Neural Networks},
     url = {https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
     volume = {25},
     year = {2012}
}

@inproceedings{cifar10-cifar100,
    author = {Krizhevsky, Alex},
    title = {Learning Multiple Layers of Features from Tiny Images},
    year = {2009}
}

@techreport{WelinderEtal2010,
	Author = {P. Welinder and S. Branson and T. Mita and C. Wah and F. Schroff and S. Belongie and P. Perona},
	Institution = {California Institute of Technology},
	Number = {CNS-TR-2010-001},
	Title = {{Caltech-UCSD Birds 200}},
	Year = {2010}
}

@article{cifar10,
title= {CIFAR-10 (Canadian Institute for Advanced Research)},
journal= {},
author= {Alex Krizhevsky and Vinod Nair and Geoffrey Hinton},
year= {},
url= {http://www.cs.toronto.edu/~kriz/cifar.html},
abstract= {The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. 

The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. },
keywords= {Dataset},
terms= {}
}


@article{cifar100,
title= {CIFAR-100 (Canadian Institute for Advanced Research)},
journal= {},
author= {Alex Krizhevsky and Vinod Nair and Geoffrey Hinton},
year= {},
url= {http://www.cs.toronto.edu/~kriz/cifar.html},
abstract= {This dataset is just like the CIFAR-10, except it has 100 classes containing 600 images each. There are 500 training images and 100 testing images per class. The 100 classes in the CIFAR-100 are grouped into 20 superclasses. Each image comes with a "fine" label (the class to which it belongs) and a "coarse" label (the superclass to which it belongs).
Here is the list of classes in the CIFAR-100:

Superclass	Classes
aquatic mammals	beaver, dolphin, otter, seal, whale
fish	aquarium fish, flatfish, ray, shark, trout
flowers	orchids, poppies, roses, sunflowers, tulips
food containers	bottles, bowls, cans, cups, plates
fruit and vegetables	apples, mushrooms, oranges, pears, sweet peppers
household electrical devices	clock, computer keyboard, lamp, telephone, television
household furniture	bed, chair, couch, table, wardrobe
insects	bee, beetle, butterfly, caterpillar, cockroach
large carnivores	bear, leopard, lion, tiger, wolf
large man-made outdoor things	bridge, castle, house, road, skyscraper
large natural outdoor scenes	cloud, forest, mountain, plain, sea
large omnivores and herbivores	camel, cattle, chimpanzee, elephant, kangaroo
medium-sized mammals	fox, porcupine, possum, raccoon, skunk
non-insect invertebrates	crab, lobster, snail, spider, worm
people	baby, boy, girl, man, woman
reptiles	crocodile, dinosaur, lizard, snake, turtle
small mammals	hamster, mouse, rabbit, shrew, squirrel
trees	maple, oak, palm, pine, willow
vehicles 1	bicycle, bus, motorcycle, pickup truck, train
vehicles 2	lawn-mower, rocket, streetcar, tank, tractor

Yes, I know mushrooms aren't really fruit or vegetables and bears aren't really carnivores. },
keywords= {Dataset},
terms= {}
}

@inproceedings{CelebA,
 title = {Deep Learning Face Attributes in the Wild},
 author = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
 booktitle = {Proceedings of International Conference on Computer Vision (ICCV)},
 month = {December},
 year = {2015} 
}

@inproceedings{AlexNet,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
 pages = {1097--1105},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}

