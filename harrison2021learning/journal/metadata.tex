% DO NOT EDIT - automatically generated from metadata.yaml

\def \codeURL{https://github.com/MatPrst/deceptive-attention-reproduced}
\def \codeDOI{10.5281/zenodo.4692668}
\def \codeSWH{}
\def \dataURL{https://github.com/MatPrst/deceptive-attention-reproduced/tree/main/deceptive-attention/src/classification/data}
\def \dataDOI{10.5281/zenodo.4686793}
\def \editorNAME{}
\def \editorORCID{}
\def \reviewerINAME{}
\def \reviewerIORCID{}
\def \reviewerIINAME{}
\def \reviewerIIORCID{}
\def \dateRECEIVED{01 November 2018}
\def \dateACCEPTED{}
\def \datePUBLISHED{}
\def \articleTITLE{[Re] Reproducing Learning to Deceive With Attention-Based Explanations}
\def \articleTYPE{Replication}
\def \articleDOMAIN{ML Reproducibility Challenge 2020}
\def \articleBIBLIOGRAPHY{bibliography.bib}
\def \articleYEAR{2021}
\def \reviewURL{https://openreview.net/forum?id=-rn9m0Gt6AQ}
\def \articleABSTRACT{Pruthi et al. (2020) experimentally show that attention-based explanations can be manipulated, by adding a model-agnostic penalty term to the loss function that penalises the model for attending to certain tokens which have been shown to be crucial for high performance (termed impermissible tokens). Despite this penalty resulting in substantial reductions of attention masses of impermissible tokens, the authors find that models still use these tokens as evidenced by no observed drop in accuracy. Given the implications of their findings for the use of attention-based explanations, we seek to reproduce their core results, while replicating others including their BERT-based model. We manage to both successfully reproduce and replicate the majority of their findings, providing further evidence to the claims in the original paper.}
\def \replicationCITE{Danish Pruthi, Mansi Gupta, Bhuwan Dhingra, Graham Neubig, and Zachary C. Lipton. 2020. Learning to deceive with attention-based explanations. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4782â€“4793, Online. Association for Computational Linguistics.}
\def \replicationBIB{pruthi-etal-2020-learning}
\def \replicationURL{https://arxiv.org/abs/1909.07913}
\def \replicationDOI{10.18653/v1/2020.acl-main.432}
\def \contactNAME{Rahel Habacker}
\def \contactEMAIL{rahel.habacker@student.uva.nl}
\def \articleKEYWORDS{rescience c, rescience x, Python}
\def \journalNAME{ReScience C}
\def \journalVOLUME{4}
\def \journalISSUE{1}
\def \articleNUMBER{}
\def \articleDOI{}
\def \authorsFULL{Rahel Habacker et al.}
\def \authorsABBRV{R. Habacker et al.}
\def \authorsSHORT{Habacker et al.}
\title{\articleTITLE}
\date{}
\author[1,\orcid{0000-0001-9672-5951}]{Rahel Habacker}
\author[1,,\orcid{0000-0002-1407-3599}]{Andrew Harrison}
\author[1,,\orcid{0000-0003-1521-918X}]{Mathias Parisot}
\author[1,,\orcid{0000-0001-6213-2218}]{Ard Snijders}
\affil[1]{University of Amsterdam, Amsterdam, The Netherlands}
