@inproceedings{bilstm,
  author={A. {Graves} and J. {Schmidhuber}},
  booktitle={Proceedings. 2005 IEEE International Joint Conference on Neural Networks, 2005.}, 
  title={Framewise phoneme classification with bidirectional LSTM networks}, 
  year={2005},
  volume={4},
  number={},
  pages={2047-2052 vol. 4},
  doi={10.1109/IJCNN.2005.1556215}
}

@article{huggingface,
  author    = {Thomas Wolf and
               Lysandre Debut and
               Victor Sanh and
               Julien Chaumond and
               Clement Delangue and
               Anthony Moi and
               Pierric Cistac and
               Tim Rault and
               R{\'{e}}mi Louf and
               Morgan Funtowicz and
               Jamie Brew},
  title     = {HuggingFace's Transformers: State-of-the-art Natural Language Processing},
  journal   = {CoRR},
  volume    = {abs/1910.03771},
  year      = {2019},
  url       = {http://arxiv.org/abs/1910.03771},
  archivePrefix = {arXiv},
  eprint    = {1910.03771},
  timestamp = {Tue, 02 Jun 2020 12:49:01 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1910-03771.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{pruthi-etal-2020-learning,
    title = "Learning to Deceive with Attention-Based Explanations",
    author = "Pruthi, Danish  and
      Gupta, Mansi  and
      Dhingra, Bhuwan  and
      Neubig, Graham  and
      Lipton, Zachary C.",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.432",
    doi = "10.18653/v1/2020.acl-main.432",
    pages = "4782--4793",
    abstract = "Attention mechanisms are ubiquitous components in neural architectures applied to natural language processing. In addition to yielding gains in predictive accuracy, attention weights are often claimed to confer interpretability, purportedly useful both for providing insights to practitioners and for explaining why a model makes its decisions to stakeholders. We call the latter use of attention mechanisms into question by demonstrating a simple method for training models to produce deceptive attention masks. Our method diminishes the total weight assigned to designated impermissible tokens, even when the models can be shown to nevertheless rely on these features to drive predictions. Across multiple models and tasks, our approach manipulates attention weights while paying surprisingly little cost in accuracy. Through a human study, we show that our manipulated attention-based explanations deceive people into thinking that predictions from a model biased against gender minorities do not rely on the gender. Consequently, our results cast doubt on attention{'}s reliability as a tool for auditing algorithms in the context of fairness and accountability.",
}

@misc{kingma2017adam,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{elliott2016multi30k,
      title={Multi30K: Multilingual English-German Image Descriptions}, 
      author={Desmond Elliott and Stella Frank and Khalil Sima'an and Lucia Specia},
      year={2016},
      eprint={1605.00459},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{jain2019attention,
  title={Attention is not Explanation},
  author={Jain, Sarthak and Wallace, Byron C},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={3543--3556},
  year={2019}
}

@article{galassi2020attention,
  title={Attention in natural language processing},
  author={Galassi, Andrea and Lippi, Marco and Torroni, Paolo},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2020},
  publisher={IEEE}
}

@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
  journal={arXiv preprint arXiv:1706.03762},
  year={2017}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{serrano2019attention,
  title={Is Attention Interpretable?},
  author={Serrano, Sofia and Smith, Noah A},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={2931--2951},
  year={2019}
}

@inproceedings{wiegreffe2019attention,
  title={Attention is not not Explanation},
  author={Wiegreffe, Sarah and Pinter, Yuval},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={11--20},
  year={2019}
}

@inproceedings{ribeiro2016should,
  title={" Why should i trust you?" Explaining the predictions of any classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1135--1144},
  year={2016}
}

@inproceedings{tenney2019bert,
  title={BERT Rediscovers the Classical NLP Pipeline},
  author={Tenney, Ian and Das, Dipanjan and Pavlick, Ellie},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={4593--4601},
  year={2019}
}

@inproceedings{grefenstette2015learning,
  title={Learning to transduce with unbounded memory},
  author={Grefenstette, Edward and Hermann, Karl Moritz and Suleyman, Mustafa and Blunsom, Phil},
  booktitle={Proceedings of the 28th International Conference on Neural Information Processing Systems-Volume 2},
  pages={1828--1836},
  year={2015}
}

@inproceedings{papineni-etal-2002-bleu,
    title = "{B}leu: a Method for Automatic Evaluation of Machine Translation",
    author = "Papineni, Kishore  and
      Roukos, Salim  and
      Ward, Todd  and
      Zhu, Wei-Jing",
    booktitle = "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2002",
    address = "Philadelphia, Pennsylvania, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P02-1040",
    doi = "10.3115/1073083.1073135",
    pages = "311--318",
}

@article{brunner2019identifiability,
  title={On identifiability in transformers},
  author={Brunner, Gino and Liu, Yang and Pascual, Damian and Richter, Oliver and Ciaramita, Massimiliano and Wattenhofer, Roger},
  journal={arXiv preprint arXiv:1908.04211},
  year={2019}
}

@inproceedings{clark2019does,
  title={What Does BERT Look at? An Analysis of BERTâ€™s Attention},
  author={Clark, Kevin and Khandelwal, Urvashi and Levy, Omer and Manning, Christopher D},
  booktitle={Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP},
  pages={276--286},
  year={2019}
}

@inproceedings{letarte2018importance,
  title={Importance of self-attention for sentiment analysis},
  author={Letarte, Ga{\"e}l and Paradis, Fr{\'e}d{\'e}rik and Gigu{\`e}re, Philippe and Laviolette, Fran{\c{c}}ois},
  booktitle={Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP},
  pages={267--275},
  year={2018}
}

@article{vashishth2019attention,
  title={Attention interpretability across nlp tasks},
  author={Vashishth, Shikhar and Upadhyay, Shyam and Tomar, Gaurav Singh and Faruqui, Manaal},
  journal={arXiv preprint arXiv:1909.11218},
  year={2019}
}

@inproceedings{de2019bias,
  title={Bias in bios: A case study of semantic representation bias in a high-stakes setting},
  author={De-Arteaga, Maria and Romanov, Alexey and Wallach, Hanna and Chayes, Jennifer and Borgs, Christian and Chouldechova, Alexandra and Geyik, Sahin and Kenthapadi, Krishnaram and Kalai, Adam Tauman},
  booktitle={proceedings of the Conference on Fairness, Accountability, and Transparency},
  pages={120--128},
  year={2019}
}

@inproceedings{socher-etal-2013-recursive,
    title = "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
    author = "Socher, Richard  and
      Perelygin, Alex  and
      Wu, Jean  and
      Chuang, Jason  and
      Manning, Christopher D.  and
      Ng, Andrew  and
      Potts, Christopher",
    booktitle = "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
    month = oct,
    year = "2013",
    address = "Seattle, Washington, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D13-1170",
    pages = "1631--1642",
}

@inproceedings{neubig-etal-2019-compare,
    title = "compare-mt: A Tool for Holistic Comparison of Language Generation Systems",
    author = "Neubig, Graham  and
      Dou, Zi-Yi  and
      Hu, Junjie  and
      Michel, Paul  and
      Pruthi, Danish  and
      Wang, Xinyi",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics (Demonstrations)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-4007",
    doi = "10.18653/v1/N19-4007",
    pages = "35--41",
    abstract = "In this paper, we describe compare-mt, a tool for holistic analysis and comparison of the results of systems for language generation tasks such as machine translation. The main goal of the tool is to give the user a high-level and coherent view of the salient differences between systems that can then be used to guide further analysis or system improvement. It implements a number of tools to do so, such as analysis of accuracy of generation of particular types of words, bucketed histograms of sentence accuracies or counts based on salient characteristics, and extraction of characteristic n-grams for each system. It also has a number of advanced features such as use of linguistic labels, source side data, or comparison of log likelihoods for probabilistic models, and also aims to be easily extensible by users to new types of analysis. compare-mt is a pure-Python open source package, that has already proven useful to generate analyses that have been used in our published papers. Demo Video: https://youtu.be/NyJEQT7t2CA",
}

@book{BirdKleinLoper09,
  abstract = {This book offers a highly accessible introduction to Natural Language Processing, the field that underpins a variety of language technologies ranging from predictive text and email filtering to automatic summarization and translation. Using NLTK, you'll learn how to write Python programs to analyze the structure and meaning of texts, drawing on techniques from the fields of linguistics and artificial intelligence.},
  added-at = {2016-12-06T16:29:36.000+0100},
  address = {Beijing},
  author = {Bird, Steven and Klein, Ewan and Loper, Edward},
  biburl = {https://www.bibsonomy.org/bibtex/2c90dc59441d01c8bef58a947274164d4/flint63},
  doi = {http://my.safaribooksonline.com/9780596516499},
  file = {O'Reilly eBook:2009/BirdKleinLoper09.pdf:PDF;O'Reilly Product page:http\://shop.oreilly.com/product/9780596516499.do:URL;Related Web Site:http\://www.nltk.org/:URL;Safari:https\://www.safaribooksonline.com/library/view/natural-language-processing/9780596803346/:URL},
  groups = {public},
  interhash = {5408d7da097b9cd81239c238da8bfaf4},
  intrahash = {c90dc59441d01c8bef58a947274164d4},
  isbn = {978-0-596-51649-9},
  keywords = {01841 103 book safari ai software development language processing text python framework},
  publisher = {O'Reilly},
  timestamp = {2018-04-16T12:35:20.000+0200},
  title = {Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit},
  url = {http://www.nltk.org/book},
  username = {flint63},
  year = 2009
}

@inproceedings{dyer-etal-2013-simple,
    title = "A Simple, Fast, and Effective Reparameterization of {IBM} Model 2",
    author = "Dyer, Chris  and
      Chahuneau, Victor  and
      Smith, Noah A.",
    booktitle = "Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2013",
    address = "Atlanta, Georgia",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N13-1073",
    pages = "644--648",
}