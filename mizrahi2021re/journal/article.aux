\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\abx@aux@refcontext{none/global//global/global}
\HyPL@Entry{0<</S/D>>}
\babel@aux{american}{}
\pgfsyspdfmark {pgfid1}{8391059}{49131591}
\newmarginnote{note.1.1}{{1}{8391059sp}}
\abx@aux@cite{bengio1994learning}
\abx@aux@segm{0}{0}{bengio1994learning}
\abx@aux@cite{zhang2019analysis}
\abx@aux@segm{0}{0}{zhang2019analysis}
\abx@aux@cite{zhang2019analysis}
\abx@aux@segm{0}{0}{zhang2019analysis}
\abx@aux@cite{menon_can_2019}
\abx@aux@segm{0}{0}{menon_can_2019}
\abx@aux@cite{menon_can_2019}
\abx@aux@segm{0}{0}{menon_can_2019}
\abx@aux@cite{ekholm1982model}
\abx@aux@segm{0}{0}{ekholm1982model}
\abx@aux@cite{menon2015learning}
\abx@aux@segm{0}{0}{menon2015learning}
\abx@aux@cite{zhang_generalized_2018}
\abx@aux@segm{0}{0}{zhang_generalized_2018}
\abx@aux@cite{ekholm1982model}
\abx@aux@segm{0}{0}{ekholm1982model}
\abx@aux@cite{menon2015learning}
\abx@aux@segm{0}{0}{menon2015learning}
\abx@aux@cite{zhang_generalized_2018}
\abx@aux@segm{0}{0}{zhang_generalized_2018}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}{section.1}\protected@file@percent }
\newlabel{eqn:phuber-ce}{{1}{3}{Introduction}{equation.1.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{3}{section.2}\protected@file@percent }
\abx@aux@cite{van_rooyen_learning_2015}
\abx@aux@segm{0}{0}{van_rooyen_learning_2015}
\abx@aux@cite{zhang_generalized_2018}
\abx@aux@segm{0}{0}{zhang_generalized_2018}
\abx@aux@cite{huber_robust_1964}
\abx@aux@segm{0}{0}{huber_robust_1964}
\abx@aux@cite{menon_can_2019}
\abx@aux@segm{0}{0}{menon_can_2019}
\abx@aux@cite{long_random_2010}
\abx@aux@segm{0}{0}{long_random_2010}
\abx@aux@cite{long_random_2010}
\abx@aux@segm{0}{0}{long_random_2010}
\abx@aux@cite{ding_statistical_2013}
\abx@aux@segm{0}{0}{ding_statistical_2013}
\abx@aux@cite{ding_statistical_2013}
\abx@aux@segm{0}{0}{ding_statistical_2013}
\abx@aux@cite{harris_array_2020}
\abx@aux@segm{0}{0}{harris_array_2020}
\abx@aux@cite{virtanen_scipy_2020}
\abx@aux@segm{0}{0}{virtanen_scipy_2020}
\abx@aux@cite{yadan_hydra_2019}
\abx@aux@segm{0}{0}{yadan_hydra_2019}
\abx@aux@cite{long_random_2010}
\abx@aux@segm{0}{0}{long_random_2010}
\abx@aux@cite{long_random_2010}
\abx@aux@segm{0}{0}{long_random_2010}
\abx@aux@cite{long_random_2010}
\abx@aux@segm{0}{0}{long_random_2010}
\abx@aux@cite{long_random_2010}
\abx@aux@segm{0}{0}{long_random_2010}
\newlabel{eqn:huber-logistic}{{2}{4}{Background}{equation.2.2}{}}
\newlabel{eqn:phuber-logistic}{{3}{4}{Background}{equation.2.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3}Synthetic experiments}{4}{section.3}\protected@file@percent }
\newlabel{sec:synthetic}{{3}{4}{Synthetic experiments}{section.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Long and Servedio dataset}{4}{subsection.3.1}\protected@file@percent }
\newlabel{sec:long&servedio}{{3.1}{4}{Long and Servedio dataset}{subsection.3.1}{}}
\abx@aux@cite{ding_statistical_2013}
\abx@aux@segm{0}{0}{ding_statistical_2013}
\abx@aux@cite{ding_statistical_2013}
\abx@aux@segm{0}{0}{ding_statistical_2013}
\abx@aux@cite{long_random_2010}
\abx@aux@segm{0}{0}{long_random_2010}
\abx@aux@cite{long_random_2010}
\abx@aux@segm{0}{0}{long_random_2010}
\abx@aux@cite{ding_statistical_2013}
\abx@aux@segm{0}{0}{ding_statistical_2013}
\abx@aux@cite{ding_statistical_2013}
\abx@aux@segm{0}{0}{ding_statistical_2013}
\abx@aux@cite{long_random_2010}
\abx@aux@segm{0}{0}{long_random_2010}
\abx@aux@cite{long_random_2010}
\abx@aux@segm{0}{0}{long_random_2010}
\abx@aux@cite{ding_statistical_2013}
\abx@aux@segm{0}{0}{ding_statistical_2013}
\abx@aux@cite{ding_statistical_2013}
\abx@aux@segm{0}{0}{ding_statistical_2013}
\abx@aux@cite{paszke_pytorch_2019}
\abx@aux@segm{0}{0}{paszke_pytorch_2019}
\abx@aux@cite{yadan_hydra_2019}
\abx@aux@segm{0}{0}{yadan_hydra_2019}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Outliers dataset}{5}{subsection.3.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:long&servedio-0.45}{{1a}{5}{Long and Servedio ($\rho = 0.45$)\relax }{figure.caption.1}{}}
\newlabel{sub@fig:long&servedio-0.45}{{a}{5}{Long and Servedio ($\rho = 0.45$)\relax }{figure.caption.1}{}}
\newlabel{fig:long&servedio-0.2}{{1b}{5}{Long and Servedio ($\rho = 0.2$)\relax }{figure.caption.1}{}}
\newlabel{sub@fig:long&servedio-0.2}{{b}{5}{Long and Servedio ($\rho = 0.2$)\relax }{figure.caption.1}{}}
\newlabel{fig:ding-outlier}{{1c}{5}{Effect of outliers\relax }{figure.caption.1}{}}
\newlabel{sub@fig:ding-outlier}{{c}{5}{Effect of outliers\relax }{figure.caption.1}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Reproduction of \citeauthor {long_random_2010}\supercite {long_random_2010} and \citeauthor {ding_statistical_2013}\supercite {ding_statistical_2013} experiments. In the Ding experiment (c), the solid curve denotes empirical risk without outliers, while the dashed curve denotes empirical risk with outliers. \relax }}{5}{figure.caption.1}\protected@file@percent }
\newlabel{fig:synthetic}{{1}{5}{Reproduction of \citet {long_random_2010} and \citet {ding_statistical_2013} experiments. In the Ding experiment (c), the solid curve denotes empirical risk without outliers, while the dashed curve denotes empirical risk with outliers. \relax }{figure.caption.1}{}}
\abx@aux@cite{lecun_gradient-based_1998}
\abx@aux@segm{0}{0}{lecun_gradient-based_1998}
\abx@aux@cite{kingma_adam_2017}
\abx@aux@segm{0}{0}{kingma_adam_2017}
\abx@aux@cite{van_rooyen_learning_2015}
\abx@aux@segm{0}{0}{van_rooyen_learning_2015}
\abx@aux@cite{zhang_generalized_2018}
\abx@aux@segm{0}{0}{zhang_generalized_2018}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4}Real-world experiments}{6}{section.4}\protected@file@percent }
\newlabel{sec:realworld}{{4}{6}{Real-world experiments}{section.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}MNIST}{6}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Methodology}{6}{subsubsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Computational requirements}{6}{subsubsection.4.1.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}Results}{6}{subsubsection.4.1.3}\protected@file@percent }
\abx@aux@cite{krizhevsky_learning_2009}
\abx@aux@segm{0}{0}{krizhevsky_learning_2009}
\abx@aux@cite{zagoruyko_wide_2016}
\abx@aux@segm{0}{0}{zagoruyko_wide_2016}
\abx@aux@cite{zagoruyko_wide_2016}
\abx@aux@segm{0}{0}{zagoruyko_wide_2016}
\abx@aux@cite{he_deep_2015}
\abx@aux@segm{0}{0}{he_deep_2015}
\abx@aux@cite{liu_kuangliupytorch-cifar_2017}
\abx@aux@segm{0}{0}{liu_kuangliupytorch-cifar_2017}
\abx@aux@cite{liu_kuangliupytorch-cifar_2017}
\abx@aux@segm{0}{0}{liu_kuangliupytorch-cifar_2017}
\abx@aux@cite{he_deep_2015}
\abx@aux@segm{0}{0}{he_deep_2015}
\abx@aux@cite{he_deep_2015}
\abx@aux@segm{0}{0}{he_deep_2015}
\abx@aux@cite{imagenet_cvpr09}
\abx@aux@segm{0}{0}{imagenet_cvpr09}
\abx@aux@cite{devries_improved_2017}
\abx@aux@segm{0}{0}{devries_improved_2017}
\abx@aux@cite{zhang_mixup_2018}
\abx@aux@segm{0}{0}{zhang_mixup_2018}
\abx@aux@cite{li_dividemix_2020}
\abx@aux@segm{0}{0}{li_dividemix_2020}
\abx@aux@cite{zhang_lookahead_2019}
\abx@aux@segm{0}{0}{zhang_lookahead_2019}
\abx@aux@cite{devries_improved_2017}
\abx@aux@segm{0}{0}{devries_improved_2017}
\abx@aux@cite{zhang_mixup_2018}
\abx@aux@segm{0}{0}{zhang_mixup_2018}
\abx@aux@cite{li_dividemix_2020}
\abx@aux@segm{0}{0}{li_dividemix_2020}
\abx@aux@cite{zhang_lookahead_2019}
\abx@aux@segm{0}{0}{zhang_lookahead_2019}
\abx@aux@cite{liu_kuangliupytorch-cifar_2017}
\abx@aux@segm{0}{0}{liu_kuangliupytorch-cifar_2017}
\abx@aux@cite{liu_kuangliupytorch-cifar_2017}
\abx@aux@segm{0}{0}{liu_kuangliupytorch-cifar_2017}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Reproduction of the MNIST experiments. The mean and standard error of the test accuracy over 3 trials is reported. The highlighted cells correspond to the best performing loss at a given $\rho $. \relax }}{7}{table.caption.2}\protected@file@percent }
\newlabel{tab:mnist-results}{{1}{7}{Reproduction of the MNIST experiments. The mean and standard error of the test accuracy over 3 trials is reported. The highlighted cells correspond to the best performing loss at a given $\rho $. \relax }{table.caption.2}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Test accuracy of LeNet-5 on MNIST\relax }}{7}{figure.caption.3}\protected@file@percent }
\newlabel{fig:mnist-comparison}{{2}{7}{Test accuracy of LeNet-5 on MNIST\relax }{figure.caption.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}CIFAR-10 and CIFAR-100}{7}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Methodology}{7}{subsubsection.4.2.1}\protected@file@percent }
\abx@aux@cite{nesterov_method_1983}
\abx@aux@segm{0}{0}{nesterov_method_1983}
\abx@aux@cite{sutskever_importance_2013}
\abx@aux@segm{0}{0}{sutskever_importance_2013}
\abx@aux@cite{devries_improved_2017}
\abx@aux@segm{0}{0}{devries_improved_2017}
\abx@aux@cite{devries_improved_2017}
\abx@aux@segm{0}{0}{devries_improved_2017}
\abx@aux@cite{micikevicius_mixed_2017}
\abx@aux@segm{0}{0}{micikevicius_mixed_2017}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Computational requirements}{8}{subsubsection.4.2.2}\protected@file@percent }
\newlabel{cifar-compute-reqs}{{4.2.2}{8}{Computational requirements}{subsubsection.4.2.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}Results}{8}{subsubsection.4.2.3}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Reproduction of the CIFAR-10 and CIFAR-100 experiments. The mean and standard error of the test accuracy over 3 trials is reported. The highlighted cells correspond to the best performing loss at a given $\rho $. CIFAR-100 PHuber-CE with $\tau =50$ is an additional experiment that was not performed in the original paper. \relax }}{9}{table.caption.4}\protected@file@percent }
\newlabel{tab:cifar-results}{{2}{9}{Reproduction of the CIFAR-10 and CIFAR-100 experiments. The mean and standard error of the test accuracy over 3 trials is reported. The highlighted cells correspond to the best performing loss at a given $\rho $. CIFAR-100 PHuber-CE with $\tau =50$ is an additional experiment that was not performed in the original paper. \relax }{table.caption.4}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Test accuracy of ResNet-50 on CIFAR-10\relax }}{9}{figure.caption.5}\protected@file@percent }
\newlabel{fig:cifar10-comparison}{{3}{9}{Test accuracy of ResNet-50 on CIFAR-10\relax }{figure.caption.5}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Test accuracy of ResNet-50 on CIFAR-100\relax }}{9}{figure.caption.6}\protected@file@percent }
\newlabel{fig:cifar100-comparison}{{4}{9}{Test accuracy of ResNet-50 on CIFAR-100\relax }{figure.caption.6}{}}
\abx@aux@cite{long_random_2010}
\abx@aux@segm{0}{0}{long_random_2010}
\abx@aux@cite{long_random_2010}
\abx@aux@segm{0}{0}{long_random_2010}
\abx@aux@cite{ding_statistical_2013}
\abx@aux@segm{0}{0}{ding_statistical_2013}
\abx@aux@cite{ding_statistical_2013}
\abx@aux@segm{0}{0}{ding_statistical_2013}
\abx@aux@cite{akiba2019optuna}
\abx@aux@segm{0}{0}{akiba2019optuna}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{10}{section.5}\protected@file@percent }
\newlabel{sec:discussion}{{5}{10}{Discussion}{section.5}{}}
\abx@aux@cite{menon_can_2019}
\abx@aux@segm{0}{0}{menon_can_2019}
\abx@aux@cite{menon_can_2019}
\abx@aux@segm{0}{0}{menon_can_2019}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{11}{section.6}\protected@file@percent }
\newlabel{sec:conclusion}{{6}{11}{Conclusion}{section.6}{}}
\abx@aux@cite{long_random_2010}
\abx@aux@segm{0}{0}{long_random_2010}
\abx@aux@cite{long_random_2010}
\abx@aux@segm{0}{0}{long_random_2010}
\abx@aux@cite{long_random_2010}
\abx@aux@segm{0}{0}{long_random_2010}
\abx@aux@cite{long_random_2010}
\abx@aux@segm{0}{0}{long_random_2010}
\abx@aux@cite{menon_can_2019}
\abx@aux@segm{0}{0}{menon_can_2019}
\abx@aux@read@bbl@mdfivesum{614308059D75D8C607BE066FED4D1723}
\abx@aux@refcontextdefaultsdone
\abx@aux@defaultrefcontext{0}{bengio1994learning}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{zhang2019analysis}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{menon_can_2019}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{ekholm1982model}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{menon2015learning}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{zhang_generalized_2018}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{van_rooyen_learning_2015}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{huber_robust_1964}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{long_random_2010}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{ding_statistical_2013}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{harris_array_2020}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{virtanen_scipy_2020}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{yadan_hydra_2019}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{paszke_pytorch_2019}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{lecun_gradient-based_1998}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{kingma_adam_2017}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{krizhevsky_learning_2009}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{zagoruyko_wide_2016}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{he_deep_2015}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{liu_kuangliupytorch-cifar_2017}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{imagenet_cvpr09}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{devries_improved_2017}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{zhang_mixup_2018}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{li_dividemix_2020}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{zhang_lookahead_2019}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{nesterov_method_1983}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{sutskever_importance_2013}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{micikevicius_mixed_2017}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{akiba2019optuna}{none/global//global/global}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {A}Decision boundaries in the Long and Servedio experiment}{13}{appendix.A}\protected@file@percent }
\newlabel{fig:logistic}{{5a}{13}{Logistic\relax }{figure.caption.7}{}}
\newlabel{sub@fig:logistic}{{a}{13}{Logistic\relax }{figure.caption.7}{}}
\newlabel{fig:huber}{{5b}{13}{Huberised\relax }{figure.caption.7}{}}
\newlabel{sub@fig:huber}{{b}{13}{Huberised\relax }{figure.caption.7}{}}
\newlabel{fig:phuber}{{5c}{13}{Partially Huberised\relax }{figure.caption.7}{}}
\newlabel{sub@fig:phuber}{{c}{13}{Partially Huberised\relax }{figure.caption.7}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Decision boundaries in the reproduced \citeauthor {long_random_2010}\supercite {long_random_2010} experiment, with label noise flip probability $\rho = 0.2$. The logistic and Huberised logistic loss misclassify samples generated from the two {\bfseries  penalizer} Gaussians centered around $\pm (\gamma , -\gamma )$, resulting in $50\%$ test accuracy. The partially Huberised logistic loss does not succumb to label noise, achieving near-perfect discrimination.\relax }}{13}{figure.caption.7}\protected@file@percent }
\newlabel{fig:syntheticboundaries}{{5}{13}{Decision boundaries in the reproduced \citet {long_random_2010} experiment, with label noise flip probability $\rho = 0.2$. The logistic and Huberised logistic loss misclassify samples generated from the two \emph {penalizer} Gaussians centered around $\pm (\gamma , -\gamma )$, resulting in $50\%$ test accuracy. The partially Huberised logistic loss does not succumb to label noise, achieving near-perfect discrimination.\relax }{figure.caption.7}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {B}Effect of the label noise seed on the real-world experiments}{13}{appendix.B}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Impact of the random seed used to generate label noise. The mean and standard error of the test accuracy over 3 trials is reported. This subset of experiments was chosen to include both a baseline and a partially Huberised loss, at the highest level of label noise. The results obtained are consistent across seeds, and differ from the original paper's results.\relax }}{13}{table.caption.8}\protected@file@percent }
\newlabel{tab:seed-results}{{3}{13}{Impact of the random seed used to generate label noise. The mean and standard error of the test accuracy over 3 trials is reported. This subset of experiments was chosen to include both a baseline and a partially Huberised loss, at the highest level of label noise. The results obtained are consistent across seeds, and differ from the original paper's results.\relax }{table.caption.8}{}}
\gdef \@abspage@last{13}
