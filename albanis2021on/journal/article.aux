\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\abx@aux@sortscheme{none}
\abx@aux@sortnamekeyscheme{global}
\abx@aux@cite{chen2020end}
\abx@aux@cite{cheng2020higherhrnet}
\abx@aux@cite{albanis2020dronepose}
\HyPL@Entry{0<</S/D>>}
\providecommand\tcolorbox@label[2]{}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\select@language{american}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\select@language{american}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\select@language{american}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\select@language{american}}
\pgfsyspdfmark {pgfid1}{8391059}{49131591}
\newmarginnote{note.1.1}{{1}{8391059sp}}
\abx@aux@cite{sattler2019understanding}
\abx@aux@cite{moai}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}{section.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2}Scope of reproducibility}{3}{section.2}}
\newlabel{sec:claims}{{2}{3}{Scope of reproducibility}{section.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{3}{section.3}}
\abx@aux@cite{sun2019deep}
\abx@aux@cite{newell2016stacked}
\abx@aux@cite{lepetit2009epnp}
\abx@aux@cite{ravi2020pytorch3d}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Indirect object pose estimation approach consisting of the \textit  {Heatmap Regression} part where HigherHRNet paper focuses on, and \textit  {Pose Retrieval} part where BPnP focuses, alongside the supervision signals.\relax }}{4}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:methodology}{{1}{4}{Indirect object pose estimation approach consisting of the \textit {Heatmap Regression} part where HigherHRNet paper focuses on, and \textit {Pose Retrieval} part where BPnP focuses, alongside the supervision signals.\relax }{figure.caption.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Model descriptions}{4}{subsection.3.1}}
\newlabel{sec:models}{{3.1}{4}{Model descriptions}{subsection.3.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Datasets}{5}{subsection.3.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}UAVA}{5}{subsubsection.3.2.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Preprocessing}{5}{subsubsection.3.2.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Hyperparameters}{5}{subsection.3.3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Experimental setup and code}{5}{subsection.3.4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Computational requirements}{6}{subsection.3.5}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Time statistics for each experiment. \leavevmode {\color  {Red}Red} and \leavevmode {\color  {Orange}orange} colors indicate the two (worst, and second worst respectively) most time-consuming experiment per drone model.\relax }}{6}{table.caption.2}}
\newlabel{tab:durations}{{1}{6}{Time statistics for each experiment. \textcolor {Red}{Red} and \textcolor {Orange}{orange} colors indicate the two (worst, and second worst respectively) most time-consuming experiment per drone model.\relax }{table.caption.2}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Hardware Components\relax }}{6}{table.caption.3}}
\newlabel{Hardware components}{{2}{6}{Hardware Components\relax }{table.caption.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{7}{section.4}}
\newlabel{sec:results}{{4}{7}{Results}{section.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Results reproducing original papers}{7}{subsection.4.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}BPnP}{7}{subsubsection.4.1.1}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces BPnP results on the UAVA dataset. We trained all models for 44 epochs and select the best among them for inference. Light \leavevmode {\color  {SeaGreen}green} with \textbf  {bold} and light \leavevmode {\color  {Cerulean}blue} indicate the best and second best performers.\relax }}{7}{table.caption.4}}
\newlabel{tab:results_bpnp}{{3}{7}{BPnP results on the UAVA dataset. We trained all models for 44 epochs and select the best among them for inference. Light \textcolor {SeaGreen}{green} with \textbf {bold} and light \textcolor {Cerulean}{blue} indicate the best and second best performers.\relax }{table.caption.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}HigherHRNet}{7}{subsubsection.4.1.2}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces HigherHRNet results on the UAVA dataset. We trained all models for 44 epochs and select the best among them for inference. Light \leavevmode {\color  {SeaGreen}green} with \textbf  {bold} and light \leavevmode {\color  {Cerulean}blue} indicate the best and second best performers.\relax }}{7}{table.caption.6}}
\newlabel{tab:results_higher}{{4}{7}{HigherHRNet results on the UAVA dataset. We trained all models for 44 epochs and select the best among them for inference. Light \textcolor {SeaGreen}{green} with \textbf {bold} and light \textcolor {Cerulean}{blue} indicate the best and second best performers.\relax }{table.caption.6}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Results beyond the BPnP paper}{7}{subsection.4.2}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Qualitative heatmap results on random samples from the test-set. The first \textbf  {two} columns depicts the M2ED drone while the last \textbf  {two} the Tello drone; with heatmaps predicted by models trained with $l_p$ and $l_h$ respectively. Evidently, heatmaps by the $l_h$ model (\textbf  {second and fourth columns} tend to keep the 2D Gaussian shape distribution, while the $l_p$ ones (\textbf  {first and third columns}) freely approximate the $(x,y)$ position enforced by the regularizer term($l_{reg}$) of the $l_p$ loss, eventually allowing for more distinguishable 2D keypoints estimations.\relax }}{8}{figure.caption.5}}
\newlabel{fig:qualitativehtmps}{{2}{8}{Qualitative heatmap results on random samples from the test-set. The first \textbf {two} columns depicts the M2ED drone while the last \textbf {two} the Tello drone; with heatmaps predicted by models trained with $l_p$ and $l_h$ respectively. Evidently, heatmaps by the $l_h$ model (\textbf {second and fourth columns} tend to keep the 2D Gaussian shape distribution, while the $l_p$ ones (\textbf {first and third columns}) freely approximate the $(x,y)$ position enforced by the regularizer term($l_{reg}$) of the $l_p$ loss, eventually allowing for more distinguishable 2D keypoints estimations.\relax }{figure.caption.5}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}BPnP vs EPnP}{8}{subsubsection.4.2.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}BPnP$_{faster}$}{8}{subsubsection.4.2.2}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces BPnP vs EPnP. Following the same approach we trained the decoder part only with $l_h$ for 30 epochs and then continue with $l_m$ for 14 epochs. Light \leavevmode {\color  {SeaGreen}green} with \textbf  {bold} indicates the best performer.\relax }}{9}{table.caption.7}}
\newlabel{tab:bpnpvsepnp}{{5}{9}{BPnP vs EPnP. Following the same approach we trained the decoder part only with $l_h$ for 30 epochs and then continue with $l_m$ for 14 epochs. Light \textcolor {SeaGreen}{green} with \textbf {bold} indicates the best performer.\relax }{table.caption.7}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces BPnP$_{faster}$ results on the UAVA dataset, following the exact training approach as original BPnP. Here we present results with models trained with $l_p$. Light \leavevmode {\color  {SeaGreen}green} with \textbf  {bold} indicates the best performer. \relax }}{9}{table.caption.8}}
\newlabel{tab:results_FasterBPnP}{{6}{9}{BPnP$_{faster}$ results on the UAVA dataset, following the exact training approach as original BPnP. Here we present results with models trained with $l_p$. Light \textcolor {SeaGreen}{green} with \textbf {bold} indicates the best performer. \relax }{table.caption.8}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces BPnP$_{faster}$ time statistics. Light \leavevmode {\color  {SeaGreen}green} with \textbf  {bold} indicates quicker performance.\relax }}{9}{table.caption.9}}
\newlabel{tab:FasterBPnP_duration}{{7}{9}{BPnP$_{faster}$ time statistics. Light \textcolor {SeaGreen}{green} with \textbf {bold} indicates quicker performance.\relax }{table.caption.9}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{9}{section.5}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}What was easy}{9}{subsection.5.1}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Qualitative results on random samples from the UAVA dataset from three different models. The \emph  {\color  {red}\textbf  {red}} mask indicates predictions by $l_p$ trained model, \emph  {\color  {purple}\textbf  {purple}} by $l_m$ and finally \emph  {\color  {cyan}\textbf  {cyan}} by HRNet. The drone masks are rendered by employing the predicted pose(i.e. output of the BPnP) and then blended with the original color image. The first \textbf  {three} columns depicts M2ED drone model while the rest \textbf  {three} the Tello drone. The Tello samples are cropped and zoomed-in due to its small form factor.\relax }}{10}{figure.caption.10}}
\newlabel{fig:qualitativeboth}{{3}{10}{Qualitative results on random samples from the UAVA dataset from three different models. The \emph {\color {red}\textbf {red}} mask indicates predictions by $l_p$ trained model, \emph {\color {purple}\textbf {purple}} by $l_m$ and finally \emph {\color {cyan}\textbf {cyan}} by HRNet. The drone masks are rendered by employing the predicted pose(i.e. output of the BPnP) and then blended with the original color image. The first \textbf {three} columns depicts M2ED drone model while the rest \textbf {three} the Tello drone. The Tello samples are cropped and zoomed-in due to its small form factor.\relax }{figure.caption.10}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}What was difficult}{10}{subsection.5.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Communication with original authors}{10}{subsection.5.3}}
