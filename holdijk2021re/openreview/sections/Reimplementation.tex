\section{Reimplementation of code}\label{sec:3}
This section shortly summarizes the main structure of the code accompanying this reproducibility check and provides the information needed to reproduce the experiments presented. Our reimplementation of the PGExplainer is based on the PyTorch \cite{PyTorch} framework. More specifically, it uses the third party extension of PyTorch for Graph Neural Networks called PyTorch-Geometric \cite{PyTorch-Geometric}. 

The codebase is structured for the two main tasks performed in this paper; training the GNNs that will be explained by the PGExplainer and performing a replication of the original experiments. Additional scripts are included for performing the evaluations presented in the appendix. Each script is self-contained, handling things such as loading the dataset, loading the correct model and setting the hyperparameters. Each of these things are predefined in \texttt{json} configuration files. For sections directly related to a part of the codebase we have added a link to the corresponding module on GitHub. 

\subsection{Experiment configuration files \hfill \texttt{[configs/selector.py]}}
The codebase contains a large number of predefined configuration files. These configuration files are the main working horse for making the experiments presented in this work reproducible. There are two different types of configurations, one for each of the two main tasks mentioned previously. Shared between tasks is the common occurrence of the dataset, model and seed used. If a task is to be performed a number of times to achieve an average, the seed is replaced with a list of seeds. A full description of the configuration file setup can be found in Appendix \ref{appendix:A}. 

As these configuration files provide a reliable source for all relevant information needed to perform our evaluation, we will---for the remainder of this paper---only disclose the information needed to comprehend the experiment. For details irrelevant to understanding the results---e.g. the used learning rate and specific framework versions---we refer to the provided configuration and codebase\footnote{\url{https://github.com/LarsHoldijk/RE-ParameterizedExplainerForGraphNeuralNetworks}}. We understand that this breaks the papers self-containment. However, we believe that regarding the balance between page restrictions and replicability completeness, separating the concern of replicability from paper to codebase is the correct way to go. A single source of replicability information also prevents inconsistencies between the paper and the code base. As the paper under consideration will highlight, this is a concern.