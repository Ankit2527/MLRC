\section{PGExplainer}\label{sec:PGE}
The authors start by dividing an input graph $G_o$ in two subgraphs, such that $G_o = G_s + \Delta G$. $G_s$ represents the \textit{explanatory graph} that makes important contributions towards the graph classification, while $\Delta G$ represents the remainder of the initial graph. The main task therefore is to find the optimal subgraph $G_s$. This is achieved through Mutual Information ($MI$) maximization:
\begin{align}
    \max _{G_{s}} \operatorname{MI}\left(Y_{o}, G_{s}\right)=H\left(Y_{o}\right)-H\left(Y_{o} \mid G=G_{s}\right),
\end{align}
Which uses the GNN's classification prediction $Y_o$ and its input $G_o$. The MI maximization is done by deducting the conditional entropy from the marginal entropy. Which is equivalent to minimizing the conditional entropy.

To avoid having an exploding exponential amount of candidates, the authors assume the explanatory graphs used are Gilbert random graphs \cite{Gilbert1959}, where selections of edges from the original input graph $G_o$ are conditionally independent to each other. 
Using relaxation, the learning objective is rewritten as
\begin{align}
    \min _{G_{s}} \mathbb{E}_{G_{s}}\left[H\left(Y_{o} \mid G=G_{s}\right)\right] \approx \min _{\Theta} \mathbb{E}_{G_{s} \sim q(\Theta)}\left[H\left(Y_{o} \mid G=G_{s}\right)\right],
\end{align}
where $q(\Theta)$ is the distribution of the parameterized explanatory graph. Each graph edge obtains a continuous variable in range $(0, 1)$.

A random graph $\hat{G}_s$ is sampled from edge distributions and fed to the trained GNN model obtaining prediction $\hat{Y}_s$. Following \cite{ying2019gnnexplainer}, the authors modify the conditional entropy with cross-entropy $H(Y_o,\hat{Y}_s)$, where $\hat{Y}_s$ is the prediction of the GNN model with $\hat{G}_s$ as input. Using Monte Carlo approximation, the learning objective becomes
\begin{align}
    \min _{\Omega}-\frac{1}{K} \sum_{k=1}^{K} \sum_{c=1}^{C} P_{\Phi}\left(Y=c \mid G=G_{o}\right) \log P_{\Phi}\left(Y=c \mid G=\hat{G}_{s}^{(k)}\right),
\end{align}
with $\Phi$ as the parameters in the trained GNN, $K$ as the number of sampled graphs, $C$ as the number of labels and $\hat{G}_s^{(k)}$ the $k$-th sampled graph, parameterized by $\Omega$.

Furthermore, PGExplainer is used to collectively provide explainations for multiple instances $\mathcal{I}$. The authors present the learning objective of this set of instances as follows.
\begin{align}
    \min _{\Psi}-\sum_{i \in \mathcal{I}} \sum_{k=1}^{K} \sum_{c=1}^{C} P_{\Phi}\left(Y=c \mid G=G_{o}^{(i)}\right) \log P_{\Phi}\left(Y=c \mid G=\hat{G}_{s}^{(i, k)}\right)
\end{align}
Here $\Psi$ are parameters in the explanation network, $G^{(i)}$ the input graph and $\hat{G}^{(i, k)}$ the $k$-th sampled graph for the $i$-th instance.
Using the above, the authors consider two explainer instances; one for node classification and one for graph classification. Both cases use a MLP parameterized by $\Psi$.